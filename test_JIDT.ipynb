{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import jpype as jp\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Try and initialise an MI calculator and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jarloc = \"/Users/joshua/py-hctsa-project/Toolboxes/infodynamics-dist/infodynamics.jar\"\n",
    "jp.startJVM(jp.getDefaultJVMPath(), \"-ea\", \"-Djava.class.path=\" + jarloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCalcClass = jp.JPackage(\"infodynamics.measures.continuous.gaussian\").MutualInfoCalculatorMultiVariateGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCalc = miCalcClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCalc.initialise(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCalc.setProperty('NOISE_LEVEL_TO_ADD', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.random.randn(20)\n",
    "y2 = np.random.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<java array 'double[]'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp.JArray(jp.JDouble)(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCalc.setObservations(jp.JArray(jp.JDouble)(y1), jp.JArray(jp.JDouble)(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024375638947790566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miCalc.computeAverageLocalOfObservations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Operations.IN_AutoMutualInfo import IN_AutoMutualInfo\n",
    "from Operations.CO_FirstCrossing import CO_FirstCrossing\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = np.loadtxt(\"ts1.txt\")\n",
    "ts2 = np.loadtxt(\"ts2.txt\")\n",
    "ts3 = np.loadtxt(\"ts3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IN_Initialize_MI(estMethod, extraParam=None, addNoise=False):\n",
    "    \"\"\"\n",
    "    Initialize Information Dynamics Toolkit object for MI computation.\n",
    "    \"\"\"\n",
    "    if estMethod == 'gaussian':\n",
    "        implementingClass = 'infodynamics.measures.continuous.gaussian'\n",
    "        miCalc = jp.JPackage(implementingClass).MutualInfoCalculatorMultiVariateGaussian()\n",
    "    elif estMethod == 'kernel':\n",
    "        implementingClass = 'infodynamics.measures.continuous.kernel'\n",
    "        miCalc = jp.JPackage(implementingClass).MutualInfoCalculatorMultiVariateKernel()\n",
    "    elif estMethod == 'kraskov1':\n",
    "        implementingClass = 'infodynamics.measures.continuous.kraskov'\n",
    "        miCalc = jp.JPackage(implementingClass).MutualInfoCalculatorMultiVariateKraskov1()\n",
    "    elif estMethod == 'kraskov2':\n",
    "        implementingClass = 'infodynamics.measures.continuous.kraskov'\n",
    "        miCalc = jp.JPackage(implementingClass).MutualInfoCalculatorMultiVariateKraskov2()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mutual information estimation method '{estMethod}'\")\n",
    "\n",
    "    # Add neighest neighbor option for KSG estimator\n",
    "    if estMethod in ['kraskov1', 'kraskov2']:\n",
    "        if extraParam != None:\n",
    "            miCalc.setProperty('k', extraParam) # 4th input specifies number of nearest neighbors for KSG estimator\n",
    "        else:\n",
    "            miCalc.setProperty('k', '3') # use 3 nearest neighbors for KSG estimator as default\n",
    "        \n",
    "    # Make deterministic if kraskov1 or 2 (which adds a small amount of noise to the signal by default)\n",
    "    if (estMethod in ['kraskov1', 'kraskov2']) and (addNoise == False):\n",
    "        miCalc.setProperty('NOISE_LEVEL_TO_ADD','0')\n",
    "    \n",
    "    # Specify a univariate calculation\n",
    "    miCalc.initialise(1,1)\n",
    "\n",
    "    return miCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IN_AutoMutualInfo(y, timeDelay=1, estMethod='gaussian', extraParam=None):\n",
    "    \"\"\"\n",
    "    Time-series automutual information\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : array_like\n",
    "        Input time series (column vector)\n",
    "    time_delay : int or list, optional\n",
    "        Time lag for automutual information calculation (default is 1)\n",
    "    est_method : str, optional\n",
    "        The estimation method used to compute the mutual information:\n",
    "        - 'gaussian'\n",
    "        - 'kernel'\n",
    "        - 'kraskov1'\n",
    "        - 'kraskov2'\n",
    "        (default is 'kernel')\n",
    "    extra_param : any, optional\n",
    "        Extra parameters for the estimation method (default is None)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    out : float or dict\n",
    "        Automutual information value(s)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(timeDelay, str) and timeDelay in ['ac', 'tau']:\n",
    "        timeDelay = CO_FirstCrossing(y, corr_fun='ac', threshold=0, what_out='discrete')\n",
    "        \n",
    "    y = np.asarray(y).flatten()\n",
    "    N = len(y)\n",
    "    minSamples = 5 # minimum 5 samples to compute mutual information (could make higher?)\n",
    "\n",
    "    # Loop over time delays if a vector\n",
    "    if not isinstance(timeDelay, list):\n",
    "        timeDelay = [timeDelay]\n",
    "    \n",
    "    numTimeDelays = len(timeDelay)\n",
    "    amis = np.full(numTimeDelays, np.nan)\n",
    "\n",
    "    if numTimeDelays > 1:\n",
    "        timeDelay = np.sort(timeDelay)\n",
    "    \n",
    "    # initialise the MI calculator object if using non-Gaussian estimator\n",
    "    if estMethod != 'gaussian':\n",
    "        # assumes the JVM has already been started up\n",
    "        miCalc = IN_Initialize_MI(estMethod, extraParam=extraParam, addNoise=False) # NO ADDED NOISE!\n",
    "    \n",
    "    for k, delay in enumerate(timeDelay):\n",
    "        # check enough samples to compute automutual info\n",
    "        if delay > N - minSamples:\n",
    "            # time sereis too short - keep the remaining values as NaNs\n",
    "            break\n",
    "        # form the time-delay vectors y1 and y2\n",
    "        y1 = y[:-delay]\n",
    "        y2 = y[delay:]\n",
    "\n",
    "        if estMethod == 'gaussian':\n",
    "            r, _ = stats.pearsonr(y1, y2)\n",
    "            amis[k] = -0.5*np.log(1 - r**2)\n",
    "        else:\n",
    "            # Reinitialize for Kraskov:\n",
    "            miCalc.initialise(1, 1)\n",
    "            # Set observations to time-delayed versions of the time series:\n",
    "            y1_jp = jp.JArray(jp.JDouble)(y1) # convert observations to java double\n",
    "            y2_jp = jp.JArray(jp.JDouble)(y2)\n",
    "            miCalc.setObservations(y1_jp, y2_jp)\n",
    "            # compute\n",
    "            amis[k] = miCalc.computeAverageLocalOfObservations()\n",
    "        \n",
    "    if np.isnan(amis).any():\n",
    "        print(f\"Warning: Time series (N={N}) is too short for automutual information calculations up to lags of {max(timeDelay)}\")\n",
    "    if numTimeDelays == 1:\n",
    "        # return a scalar if only one time delay\n",
    "        return amis[0]\n",
    "    else:\n",
    "        # return a dict for multiple time delays\n",
    "        return {f\"ami{delay}\": ami for delay, ami in zip(timeDelay, amis)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6192050659713346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IN_AutoMutualInfo(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PeripheryFunctions.BF_SignChange import BF_SignChange\n",
    "from Operations.CO_AutoCorr import CO_AutoCorr\n",
    "from Operations.IN_AutoMutualInfo import IN_AutoMutualInfo\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def IN_AutoMutualInfoStats(y, maxTau=None, estMethod='kernel', extraParam=None):\n",
    "    \"\"\"\n",
    "    Statistics on automutual information function of a time series.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    y (array-like) : column vector of time series.\n",
    "    estMethod (str) : input to IN_AutoMutualInfo\n",
    "    extraParam (str, int, optional) : input to IN_AutoMutualInfo\n",
    "    maxTau (int) : maximal time delay\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    out (dict) : a dictionary containing statistics on the AMIs and their pattern across the range of specified time delays.\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(y) # length of the time series\n",
    "    \n",
    "    # maxTau: the maximum time delay to investigate\n",
    "    if maxTau is None:\n",
    "        maxTau = np.ceil(N/4)\n",
    "    maxTau0 = int(maxTau)\n",
    "\n",
    "    # Don't go above N/2\n",
    "    maxTau = int(min(maxTau, np.ceil(N/2)))\n",
    "\n",
    "    # Get the AMI data\n",
    "    tDelay = list(range(1, maxTau+1))\n",
    "    ami = IN_AutoMutualInfo(y, timeDelay=tDelay, estMethod=estMethod, extraParam=extraParam)\n",
    "    ami = np.array(list(ami.values()))\n",
    "\n",
    "    out = {} # create dict for storing results\n",
    "    # Output the raw values\n",
    "    for i in range(1, maxTau0+1):\n",
    "        if i <= maxTau:\n",
    "            out[f'ami{i}'] = ami[i-1]\n",
    "        else:\n",
    "            out[f'ami{i}'] = np.nan\n",
    "\n",
    "    # Basic statistics\n",
    "    lami = len(ami)\n",
    "    out['mami'] = np.mean(ami)\n",
    "    out['stdami'] = np.std(ami)\n",
    "\n",
    "    # First minimum of mutual information across range\n",
    "    dami = np.diff(ami)\n",
    "    extremai = np.where((dami[:-1] * dami[1:]) < 0)[0]\n",
    "    out['pextrema'] = len(extremai) / (lami - 1)\n",
    "    out['fmmi'] = min(extremai) + 1 if len(extremai) > 0 else lami\n",
    "\n",
    "    # Look for periodicities in local maxima\n",
    "    maximai = np.where((dami[:-1] > 0) & (dami[1:] < 0))[0] + 1\n",
    "    dmaximai = np.diff(maximai)\n",
    "    out['pmaxima'] = len(dmaximai) / (lami // 2)\n",
    "    if len(dmaximai) > 0:\n",
    "        out['modeperiodmax'] = stats.mode(dmaximai, keepdims=True).mode[0]\n",
    "        out['pmodeperiodmax'] = np.sum(dmaximai == out['modeperiodmax']) / len(dmaximai)\n",
    "    else:\n",
    "        out['modeperiodmax'] = np.nan\n",
    "        out['pmodeperiodmax'] = np.nan\n",
    "\n",
    "    # Look for periodicities in local minima\n",
    "    minimai = np.where((dami[:-1] < 0) & (dami[1:] > 0))[0] + 1\n",
    "    dminimai = np.diff(minimai)\n",
    "    out['pminima'] = len(dminimai) / (lami // 2)\n",
    "    if len(dminimai) > 0:\n",
    "        out['modeperiodmin'] = stats.mode(dminimai, keepdims=True).mode[0]\n",
    "        out['pmodeperiodmin'] = np.sum(dminimai == out['modeperiodmin']) / len(dminimai)\n",
    "    else:\n",
    "        out['modeperiodmin'] = np.nan\n",
    "        out['pmodeperiodmin'] = np.nan\n",
    "    \n",
    "    # Number of crossings at mean/median level, percentiles\n",
    "    out['pcrossmean'] = np.mean(BF_SignChange(ami - np.mean(ami)))\n",
    "    out['pcrossmedian'] = np.mean(BF_SignChange(ami - np.median(ami)))\n",
    "    out['pcrossq10'] = np.mean(BF_SignChange(ami - np.quantile(ami, 0.1)))\n",
    "    out['pcrossq90'] = np.mean(BF_SignChange(ami - np.quantile(ami, 0.9)))\n",
    "    \n",
    "    # ac1\n",
    "    out['amiac1'] = CO_AutoCorr(ami, 1, 'Fourier')[0]\n",
    "\n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = IN_AutoMutualInfoStats(ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Operations.IN_Initialize_MI import IN_Initialize_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IN_MutualInfo(y1, y2, estMethod = 'kernel', extraParam = None):\n",
    "    \"\"\"\n",
    "    Mutual information of two data vectors.\n",
    "\n",
    "    \"\"\"\n",
    "    # Initialize miCalc object (don't add noise!):\n",
    "    miCalc = IN_Initialize_MI(estMethod=estMethod, extraParam=extraParam, addNoise=False)\n",
    "    # Set observations to two time series:\n",
    "    y1_jp = jp.JArray(jp.JDouble)(y1) # convert observations to java double\n",
    "    y2_jp = jp.JArray(jp.JDouble)(y2) # convert observations to java double\n",
    "    miCalc.setObservations(y1_jp, y2_jp)\n",
    "\n",
    "    # Compute mutual information\n",
    "    out = miCalc.computeAverageLocalOfObservations()\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Operations.CO_AutoCorr import CO_AutoCorr\n",
    "from Operations.IN_AutoMutualInfo import IN_AutoMutualInfo\n",
    "import warnings\n",
    "\n",
    "def CO_FirstMin(y, minWhat = 'mi-gaussian', extraParam = None, minNotMax = True):\n",
    "    \"\"\"\n",
    "    Time of first minimum in a given self-correlation function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like\n",
    "        The input time series.\n",
    "    minWhat : str, optional\n",
    "        The type of correlation to minimize. Options are 'ac' for autocorrelation,\n",
    "        or 'mi' for automutual information. By default, 'mi' specifies the\n",
    "        'gaussian' method from the Information Dynamics Toolkit. Other options\n",
    "        include 'mi-kernel', 'mi-kraskov1', 'mi-kraskov2' (from Information Dynamics Toolkit),\n",
    "        or 'mi-hist' (histogram-based method). Default is 'mi'.\n",
    "    extraParam : any, optional\n",
    "        An additional parameter required for the specified `minWhat` method (e.g., for Kraskov).\n",
    "    minNotMax : bool, optional\n",
    "        If True, return the maximum instead of the minimum. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The time of the first minimum (or maximum if `minNotMax` is True).\n",
    "    \"\"\"\n",
    "\n",
    "    N = len(y)\n",
    "\n",
    "    # Define the autocorrelation function\n",
    "    if minWhat in ['ac', 'corr']:\n",
    "        # Autocorrelation implemented as CO_AutoCorr\n",
    "        corrfn = lambda x : CO_AutoCorr(y, tau=x, method='Fourier')\n",
    "    elif minWhat == 'mi-hist':\n",
    "        print(\"Not implemented yet.\")\n",
    "    elif minWhat == 'mi-kraskov2':\n",
    "        # (using Information Dynamics Toolkit)\n",
    "        # extraParam is the number of nearest neighbors\n",
    "        corrfn = lambda x : IN_AutoMutualInfo(y, x, 'kraskov2', extraParam)\n",
    "    elif minWhat == 'mi-kraskov1':\n",
    "        # (using Information Dynamics Toolkit)\n",
    "        corrfn = lambda x : IN_AutoMutualInfo(y, x, 'kraskov1', extraParam)\n",
    "    elif minWhat == 'mi-kernel':\n",
    "        corrfn = lambda x : IN_AutoMutualInfo(y, x, 'kernel', extraParam)\n",
    "    elif minWhat in ['mi', 'mi-gaussian']:\n",
    "        corrfn = lambda x : IN_AutoMutualInfo(y, x, 'gaussian', extraParam)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown correlation type specified: {minWhat}\")\n",
    "    \n",
    "    # search for a minimum (incrementally through time lags until a minimum is found)\n",
    "    autoCorr = np.zeros(N-1) # pre-allocate maximum length autocorrelation vector\n",
    "    if minNotMax:\n",
    "        # FIRST LOCAL MINUMUM \n",
    "        for i in range(1, N):\n",
    "            autoCorr[i-1] = corrfn(i)\n",
    "            # Hit a NaN before got to a minimum -- there is no minimum\n",
    "            if np.isnan(autoCorr[i-1]):\n",
    "                warnings.warn(f\"No minimum in {minWhat} [[time series too short to find it?]]\")\n",
    "                out = np.nan\n",
    "            \n",
    "            # we're at a local minimum\n",
    "            if (i == 2) and (autoCorr[1] > autoCorr[0]):\n",
    "                # already increases at lag of 2 from lag of 1: a minimum (since ac(0) is maximal)\n",
    "                return 1\n",
    "            elif (i > 2) and autoCorr[i-3] > autoCorr[i-2] < autoCorr[i-1]:\n",
    "                # minimum at previous i\n",
    "                return i-1 # I found the first minimum!\n",
    "    else:\n",
    "        # FIRST LOCAL MAXIMUM\n",
    "        for i in range(1, N):\n",
    "            autoCorr[i-1] = corrfn(i)\n",
    "            # Hit a NaN before got to a max -- there is no max\n",
    "            if np.isnan(autoCorr[i-1]):\n",
    "                warnings.warn(f\"No minimum in {minWhat} [[time series too short to find it?]]\")\n",
    "                return np.nan\n",
    "\n",
    "            # we're at a local maximum\n",
    "            if i > 2 and autoCorr[i-3] < autoCorr[i-2] > autoCorr[i-1]:\n",
    "                return i-1\n",
    "\n",
    "    return N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
