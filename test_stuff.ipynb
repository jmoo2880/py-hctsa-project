{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = np.loadtxt(\"ts1.txt\")\n",
    "ts2 = np.loadtxt(\"ts2.txt\")\n",
    "ts3 = np.loadtxt(\"ts3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from Operations.SB_CoarseGrain import SB_CoarseGrain\n",
    "\n",
    "def FC_Surprise(y, whatPrior = 'dist', memory = 0.2, numGroups = 3, coarseGrainMethod = 'quantile', numIters = 500, randomSeed = None):\n",
    "    \"\"\"\n",
    "    FC_Surprise   How surprised you would be of the next data point given recent memory.\n",
    "\n",
    "    Coarse-grains the time series, turning it into a sequence of symbols of a\n",
    "    given alphabet size, num_groups, and quantifies measures of surprise of a\n",
    "    process with local memory of the past memory values of the symbolic string.\n",
    "\n",
    "    We then consider a memory length, memory, of the time series, and\n",
    "    use the data in the proceeding memory samples to inform our expectations of\n",
    "    the following sample.\n",
    "\n",
    "    The 'information gained', log(1/p), at each sample using expectations\n",
    "    calculated from the previous memory samples, is estimated.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : array_like\n",
    "        The input time series\n",
    "    what_prior : str, optional\n",
    "        The type of information to store in memory:\n",
    "        'dist': the values of the time series in the previous memory samples,\n",
    "        'T1': the one-point transition probabilities in the previous memory samples,\n",
    "        'T2': the two-point transition probabilities in the previous memory samples.\n",
    "    memory : int or float, optional\n",
    "        The memory length (either number of samples, or a proportion of the\n",
    "        time-series length, if between 0 and 1) (default: 0.2)\n",
    "    num_groups : int, optional\n",
    "        The number of groups to coarse-grain the time series into (default: 3)\n",
    "    coarse_grain_method : str, optional\n",
    "        The coarse-graining, or symbolization method:\n",
    "        'quantile': an equiprobable alphabet by the value of each time-series datapoint,\n",
    "        'updown': an equiprobable alphabet by the value of incremental changes in the time-series values,\n",
    "        'embed2quadrants': 4-letter alphabet of the quadrant each data point resides in a two-dimensional embedding space.\n",
    "    num_iters : int, optional\n",
    "        The number of iterations to repeat the procedure for.\n",
    "    random_seed : int or None, optional\n",
    "        Seed for the random number generator\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Summaries of the series of information gains, including the\n",
    "        minimum, maximum, mean, median, lower and upper quartiles, and\n",
    "        standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.asarray(y)\n",
    "    N = len(y) # time series length\n",
    "\n",
    "    # specify memory as a proportion of the time-series length\n",
    "    if isinstance(memory, float) and (0 < memory < 1):\n",
    "        # if float, then must be a proportion of the time series length\n",
    "        memory = int(np.ceil(memory * N))\n",
    "        \n",
    "    \n",
    "    # Course Grain\n",
    "    yth = SB_CoarseGrain(y, coarseGrainMethod, numGroups)\n",
    "    # Select random samples to test\n",
    "    np.random.seed(randomSeed) # control random seed (for reproducibility)\n",
    "    rs = np.random.permutation(N - memory) + memory # Can't do beginning of time series, up to memory\n",
    "    rs.sort() # Just use a random sample of numIters points to test\n",
    "    rs = rs[:min(numIters, len(rs))]\n",
    "\n",
    "    # Compute empirical probabilities from time series\n",
    "    store = np.zeros(len(rs))\n",
    "    for i, r in enumerate(rs):\n",
    "        if whatPrior == 'dist':\n",
    "            p = np.mean(yth[r-memory:r] == yth[r])\n",
    "        elif whatPrior == 'T1':\n",
    "            memory_data = yth[r-memory:r]\n",
    "            in_mem = np.where(memory_data[:-1] == yth[r-1])[0]\n",
    "            p = np.mean(memory_data[in_mem+1] == yth[r]) if len(in_mem) > 0 else 0\n",
    "        elif whatPrior == 'T2':\n",
    "            memory_data = yth[r-memory:r]\n",
    "            in_mem1 = np.where(memory_data[1:-1] == yth[r-1])[0]\n",
    "            in_mem2 = np.where(memory_data[in_mem1] == yth[r-2])[0]\n",
    "            p = np.mean(memory_data[in_mem2+2] == yth[r]) if len(in_mem2) > 0 else 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method '{whatPrior}'\")\n",
    "        store[i] = p\n",
    "\n",
    "    # Information gained from next observation is log(1/p) = -log(p)\n",
    "    store[store == 0] = 1  # so that we set log(0) == 0\n",
    "    store = -np.log(store)  # transform to surprises/information gains\n",
    "\n",
    "    # Calculate statistics\n",
    "    out = {\n",
    "        'min': np.min(store[store > 0]) if np.any(store > 0) else np.nan,\n",
    "        'max': np.max(store),\n",
    "        'mean': np.mean(store),\n",
    "        'sum': np.sum(store),\n",
    "        'median': np.median(store),\n",
    "        'lq': np.quantile(store, 0.25),\n",
    "        'uq': np.quantile(store, 0.75),\n",
    "        'std': np.std(store, ddof=1)\n",
    "    }\n",
    "    \n",
    "    # t-statistic to information gain of 1\n",
    "    out['tstat'] = np.abs((out['mean'] - 1) / (out['std'] / np.sqrt(numIters))) if out['std'] != 0 else np.nan\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 1.0078579253996456,\n",
       " 'max': 1.171182981502945,\n",
       " 'mean': 1.0985538241400792,\n",
       " 'sum': 549.2769120700395,\n",
       " 'median': 1.1086626245216111,\n",
       " 'lq': 1.0642108619507773,\n",
       " 'uq': 1.1394342831883648,\n",
       " 'std': 0.042137870626112676,\n",
       " 'tstat': 52.29809834842781}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC_Surprise(ts1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
