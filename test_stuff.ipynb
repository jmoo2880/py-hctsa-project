{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = np.loadtxt(\"ts1.txt\")\n",
    "ts2 = np.loadtxt(\"ts2.txt\")\n",
    "ts3 = np.loadtxt(\"ts3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_detail(coeffs, w_name, level):\n",
    "    \"\"\"\n",
    "    Reconstruct detail coefficients at a specific level.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    coeffs : list\n",
    "        Wavelet coefficients from wavedec.\n",
    "    w_name : str\n",
    "        Wavelet name.\n",
    "    level : int\n",
    "        The level to reconstruct.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    array_like\n",
    "        Reconstructed detail coefficients.\n",
    "    \"\"\"\n",
    "    coeffs_d = [np.zeros_like(c) for c in coeffs]\n",
    "    coeffs_d[level] = coeffs[level]\n",
    "    return pywt.waverec(coeffs_d, w_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980\n"
     ]
    }
   ],
   "source": [
    "coeffs = pywt.wavedec(ts1, 'db3', level=2)\n",
    "det = pywt.upcoef('d', coeffs=coeffs[1], wavelet='db3', level=2, take=len(ts1)) # details reconstruction at level of decomp. \n",
    "x = np.sort(np.abs(det))\n",
    "print(int(np.floor(len(x) * 0.98)))\n",
    "#v2p100 = x[int(np.floor(len(x) * 0.98))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032815588962967074"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2p100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Operations.CO_FirstCrossing import CO_FirstCrossing\n",
    "\n",
    "def CO_glscf(y, alpha, beta, tau = 'tau'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Set tau to first zero-crossing of the autocorrelation function with the input 'tau'\n",
    "    if tau == 'tau':\n",
    "        tau = CO_FirstCrossing(y, 'ac', 0, 'discrete')\n",
    "    \n",
    "    # Take magnitudes of time-delayed versions of the time series\n",
    "    y1 = np.abs(y[:-tau])\n",
    "    y2 = np.abs(y[tau:])\n",
    "\n",
    "\n",
    "    p1 = np.mean(np.multiply((y1 ** alpha), (y2 ** beta)))\n",
    "    p2 = np.multiply(np.mean(y1 ** alpha), np.mean(y2 ** beta))\n",
    "    p3 = np.sqrt(np.mean(y1 ** (2*alpha)) - (np.mean(y1 ** alpha))**2)\n",
    "    p4 = np.sqrt(np.mean(y2 ** (2*beta)) - (np.mean(y2 ** beta))**2)\n",
    "\n",
    "    glscf = (p1 - p2) / (p3 * p4)\n",
    "\n",
    "    return glscf    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25284356429315435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO_glscf(ts1, 0.9, 0.4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Operations.CO_FirstCrossing import CO_FirstCrossing\n",
    "from Operations.CO_glscf import CO_glscf\n",
    "\n",
    "def CO_fzcglscf(y, alpha, beta, maxtau = None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N = len(y) # the length of the time series\n",
    "\n",
    "    if maxtau is None:\n",
    "        maxtau = N\n",
    "    \n",
    "    glscfs = np.zeros(maxtau)\n",
    "\n",
    "    for i in range(1, maxtau+1):\n",
    "        tau = i\n",
    "\n",
    "        glscfs[i-1] = CO_glscf(y, alpha, beta, tau)\n",
    "        if (i > 1) and (glscfs[i-1]*glscfs[i-2] < 0):\n",
    "            # Draw a straight line between these two and look at where it hits zero\n",
    "            out = i - 1 + glscfs[i-1]/(glscfs[i-1]-glscfs[i-2])\n",
    "            return out\n",
    "    \n",
    "    return maxtau # if the function hasn't exited yet, set output to maxtau \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "def DN_cv(x, k = 1):\n",
    "    \"\"\"\n",
    "    Coefficient of variation\n",
    "\n",
    "    Coefficient of variation of order k is sigma^k / mu^k (for sigma, standard\n",
    "    deviation and mu, mean) of a data vector, x\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    x (array-like): The input data vector\n",
    "    k (int, optional): The order of coefficient of variation (k = 1 is default)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float: The coefficient of variation of order k\n",
    "    \"\"\"\n",
    "    if not isinstance(k, int) or k < 0:\n",
    "        warnings.warn('k should probably be a positive integer')\n",
    "        # Carry on with just this warning, though\n",
    "    \n",
    "    # Compute the coefficient of variation (of order k) of the data\n",
    "    return (np.std(x, ddof=1) ** k) / (np.mean(x) ** k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.269342687595913"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DN_cv(ts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def DN_Quantile(y, p=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the quantile value at a specified proportion, p.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The input data vector\n",
    "    p (float): The quantile proportion (default is 0.5, which is the median)\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated quantile value\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If p is not a number between 0 and 1\n",
    "    \"\"\"\n",
    "    if p == 0.5:\n",
    "        print(\"Using quantile p = 0.5 (median) by default\")\n",
    "    \n",
    "    if not isinstance(p, (int, float)) or p < 0 or p > 1:\n",
    "        raise ValueError(\"p must specify a proportion, in (0,1)\")\n",
    "    \n",
    "    return np.quantile(y, p, method='hazen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def DN_nlogL_norm(y):\n",
    "    \"\"\"\n",
    "    Negative log likelihood of data coming from a Gaussian distribution.\n",
    "\n",
    "    This function fits a Gaussian distribution to the data and returns the negative\n",
    "    log likelihood of the data coming from that Gaussian distribution.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): A vector of data\n",
    "\n",
    "    Returns:\n",
    "    float: The negative log likelihood per data point\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Fit a Gaussian distribution to the data (mimicking MATLAB's normfit)\n",
    "    mu = np.mean(y)\n",
    "    sigma = np.std(y, ddof=1)  # ddof=1 for sample standard deviation\n",
    "\n",
    "    # Compute the negative log-likelihood (mimicking MATLAB's normlike)\n",
    "    n = len(y)\n",
    "    nlogL = (n/2) * np.log(2*np.pi) + n*np.log(sigma) + np.sum((y - mu)**2) / (2*sigma**2)\n",
    "\n",
    "    # Return the average negative log-likelihood\n",
    "    return nlogL / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2765413621752804"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DN_nlogL_norm(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def DN_HighLowMu(y):\n",
    "    \"\"\"\n",
    "    The highlowmu statistic.\n",
    "\n",
    "    The highlowmu statistic is the ratio of the mean of the data that is above the\n",
    "    (global) mean compared to the mean of the data that is below the global mean.\n",
    "\n",
    "    Paramters:\n",
    "    ----------\n",
    "    y (array-like): The input data vector\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: The highlowmu statistic.\n",
    "    \"\"\"\n",
    "    mu = np.mean(y) # mean of data\n",
    "    mhi = np.mean(y[y > mu]) # mean of data above the mean\n",
    "    mlo = np.mean(y[y < mu]) # mean of data below the mean\n",
    "    out = np.divide((mhi-mu), (mu-mlo)) # ratio of the differences\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0325203252032518"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DN_HighLowMu(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
