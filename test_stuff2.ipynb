{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = np.loadtxt(\"ts1.txt\")\n",
    "ts2 = np.loadtxt(\"ts2.txt\")\n",
    "ts3 = np.loadtxt(\"ts3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Operations.ST_LocalExtrema import ST_LocalExrema as STLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import *\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_file = \"/Users/joshua/Desktop/MS_shannon.so\"\n",
    "lib = CDLL(so_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.entropy.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.float64, flags='C_CONTIGUOUS'),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int,\n",
    "    ctypes.POINTER(ctypes.c_double)\n",
    "]\n",
    "lib.entropy.restype = None  # void function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(data, bin_count, depth):\n",
    "    \"\"\"\n",
    "    Calculate Shannon Entropy using the C function.\n",
    "    \n",
    "    Args:\n",
    "    data (numpy.array): Input time series data\n",
    "    bin_count (int): Number of bins for encoding\n",
    "    depth (int): Depth of the encoding\n",
    "    \n",
    "    Returns:\n",
    "    float: Calculated Shannon Entropy\n",
    "    \"\"\"\n",
    "    data = np.ascontiguousarray(data, dtype=np.float64)\n",
    "    length = len(data)\n",
    "    result = ctypes.c_double()\n",
    "    \n",
    "    lib.entropy(data, length, bin_count, depth, ctypes.byref(result))\n",
    "    \n",
    "    return result.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.258990526199341"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shannon_entropy(ts3, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numBins = 10\n",
    "numBins = [numBins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Operations.CO_HistogramAMI import CO_HistogramAMI\n",
    "from scipy import stats\n",
    "from PeripheryFunctions.BF_SignChange import BF_SignChange\n",
    "\n",
    "def CO_CompareMinAMI(y, binMethod, numBins = 10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    N = len(y)\n",
    "    # Range of time lags to consider\n",
    "    tauRange = np.arange(0, int(np.ceil(N/2))+1)\n",
    "    numTaus = len(tauRange)\n",
    "\n",
    "    # range of bin numbers to consider\n",
    "    if isinstance(numBins, int):\n",
    "        numBins = [numBins]\n",
    "    \n",
    "    numBinsRange = len(numBins)\n",
    "    amiMins = np.zeros(numBinsRange)\n",
    "\n",
    "    # Calculate automutual information\n",
    "    for i in range(numBinsRange):  # vary over number of bins in histogram\n",
    "        amis = np.zeros(numTaus)\n",
    "        for j in range(numTaus):  # vary over time lags, tau\n",
    "            amis[j] = CO_HistogramAMI(y, tauRange[j], binMethod, numBins[i])\n",
    "            if (j > 1) and ((amis[j] - amis[j-1]) * (amis[j-1] - amis[j-2]) < 0):\n",
    "                amiMins[i] = tauRange[j-1]\n",
    "                break\n",
    "        if amiMins[i] == 0:\n",
    "            amiMins[i] = tauRange[-1]\n",
    "    # basic statistics\n",
    "    out = {}\n",
    "    out['min'] = np.min(amiMins)\n",
    "    out['max'] = np.max(amiMins)\n",
    "    out['range'] = np.ptp(amiMins)\n",
    "    out['median'] = np.median(amiMins)\n",
    "    out['mean'] = np.mean(amiMins)\n",
    "    out['std'] = np.std(amiMins, ddof=1)\n",
    "    out['nunique'] = len(np.unique(amiMins))\n",
    "    out['mode'], out['modef'] = stats.mode(amiMins)\n",
    "    out['modef'] = out['modef']/numBinsRange\n",
    "\n",
    "    # converged value? \n",
    "    out['conv4'] = np.mean(amiMins[-5:])\n",
    "\n",
    "    # look for peaks (local maxima)\n",
    "    # % local maxima above 1*std from mean\n",
    "    # inspired by curious result of periodic maxima for periodic signal with\n",
    "    # bin size... ('quantiles', [2:80])\n",
    "    diff_ami_mins = np.diff(amiMins[:-1])\n",
    "    positive_diff_indices = np.where(diff_ami_mins > 0)[0]\n",
    "    sign_change_indices = BF_SignChange(diff_ami_mins, 1)\n",
    "\n",
    "    # Find the intersection of positive_diff_indices and sign_change_indices\n",
    "    loc_extr = np.intersect1d(positive_diff_indices, sign_change_indices) + 1\n",
    "    above_threshold_indices = np.where(amiMins > out['mean'] + out['std'])[0]\n",
    "    big_loc_extr = np.intersect1d(above_threshold_indices, loc_extr)\n",
    "\n",
    "    # Count the number of elements in big_loc_extr\n",
    "    out['nlocmax'] = len(big_loc_extr)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 2.0,\n",
       " 'max': 9.0,\n",
       " 'range': 7.0,\n",
       " 'median': 6.0,\n",
       " 'mean': 5.620253164556962,\n",
       " 'std': 1.7708740234361344,\n",
       " 'nunique': 8,\n",
       " 'mode': 4.0,\n",
       " 'modef': 0.189873417721519,\n",
       " 'conv4': 6.6,\n",
       " 'nlocmax': 7}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO_CompareMinAMI(ts1, 'even', range(2,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Operations.CO_HistogramAMI import CO_HistogramAMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Operations.CO_FirstCrossing import CO_FirstCrossing\n",
    "\n",
    "def CO_HistogramAMI3(y, tau = 1, meth = 'even', numBins = 10):\n",
    "    \"\"\"\n",
    "    CO_HistogramAMI: The automutual information of the distribution using histograms.\n",
    "\n",
    "    Parameters:\n",
    "    y (array-like): The input time series\n",
    "    tau (int, list or str): The time-lag(s) (default: 1)\n",
    "    meth (str): The method of computing automutual information:\n",
    "                'even': evenly-spaced bins through the range of the time series,\n",
    "                'std1', 'std2': bins that extend only up to a multiple of the\n",
    "                                standard deviation from the mean of the time series to exclude outliers,\n",
    "                'quantiles': equiprobable bins chosen using quantiles.\n",
    "    num_bins (int): The number of bins (default: 10)\n",
    "\n",
    "    Returns:\n",
    "    float or dict: The automutual information calculated in this way.\n",
    "    \"\"\"\n",
    "    # Use first zero crossing of the ACF as the time lag\n",
    "    if isinstance(tau, str) and tau in ['ac', 'tau']:\n",
    "        tau = CO_FirstCrossing(y, 'ac', 0, 'discrete')\n",
    "    \n",
    "    # Bins for the data\n",
    "    # same for both -- assume same distribution (true for stationary processes, or small lags)\n",
    "    if meth == 'even':\n",
    "        b = np.linspace(np.min(y), np.max(y), numBins + 1)\n",
    "        # Add increment buffer to ensure all points are included\n",
    "        inc = 0.1\n",
    "        b[0] -= inc\n",
    "        b[-1] += inc\n",
    "    elif meth == 'std1': # bins out to +/- 1 std\n",
    "        b = np.linspace(-1, 1, numBins + 1)\n",
    "        if np.min(y) < -1:\n",
    "            b = np.concatenate(([np.min(y) - 0.1], b))\n",
    "        if np.max(y) > 1:\n",
    "            b = np.concatenate((b, [np.max(y) + 0.1]))\n",
    "    elif meth == 'std2': # bins out to +/- 2 std\n",
    "        b = np.linspace(-2, 2, numBins + 1)\n",
    "        if np.min(y) < -2:\n",
    "            b = np.concatenate(([np.min(y) - 0.1], b))\n",
    "        if np.max(y) > 2:\n",
    "            b = np.concatenate((b, [np.max(y) + 0.1]))\n",
    "    elif meth == 'quantiles': # use quantiles with ~equal number in each bin\n",
    "        b = np.quantile(y, np.linspace(0, 1, numBins + 1))\n",
    "        b[0] -= 0.1\n",
    "        b[-1] += 0.1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method '{meth}'\")\n",
    "    \n",
    "    # Sometimes bins can be added (e.g., with std1 and std2), so need to redefine numBins\n",
    "    numBins = len(b) - 1\n",
    "\n",
    "    # Form the time-delay vectors y1 and y2\n",
    "    if not isinstance(tau, (list, np.ndarray)):\n",
    "        # if only single time delay as integer, make into a one element list\n",
    "        tau = [tau]\n",
    "\n",
    "    amis = np.zeros(len(tau))\n",
    "\n",
    "    for i, t in enumerate(tau):\n",
    "        if t == 0:\n",
    "            # for tau = 0, y1 and y2 are identical to y\n",
    "            y1 = y2 = y\n",
    "        else:\n",
    "            y1 = y[:-t]\n",
    "            y2 = y[t:]\n",
    "        # Joint distribution of y1 and y2\n",
    "        pij, _, _ = np.histogram2d(y1, y2, bins=(b, b))\n",
    "        pij = pij[:numBins, :numBins]  # joint\n",
    "        pij = pij / np.sum(pij)  # normalize\n",
    "        pi = np.sum(pij, axis=1)  # marginal\n",
    "        pj = np.sum(pij, axis=0)  # other marginal\n",
    "\n",
    "        pii = np.tile(pi, (numBins, 1)).T\n",
    "        pjj = np.tile(pj, (numBins, 1))\n",
    "\n",
    "        r = pij > 0  # Defining the range in this way, we set log(0) = 0\n",
    "        amis[i] = np.sum(pij[r] * np.log(pij[r] / pii[r] / pjj[r]))\n",
    "\n",
    "    if len(tau) == 1:\n",
    "        return amis[0]\n",
    "    else:\n",
    "        return {f'ami{i+1}': ami for i, ami in enumerate(amis)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
